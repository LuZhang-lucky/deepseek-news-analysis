{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bbce71-5172-4da8-9621-d54d4b260bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "539add82-242f-40bd-95ca-d6e89d0db7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK will not be able to resist China's tech dominance\n",
      "China's success in technology has not come out of thin air, even given the unlikely origins of the DeepSeek deep shock.\n",
      "The obscure Hangzhou hedge fund that coded a ChatGPT competitor as a side project it claims cost just $5.6m to train emerges from a concerted effort to invest in future generations of technology.\n",
      "This is not an accident. This is policy.\n",
      "The raw materials of artificial intelligence (AI) are microchips, science PhDs and data. On the latter two, China might be ahead already.\n",
      "There are on average more than 6,000 PhDs in STEM subjects (science, technology, engineering and mathematics) coming out of Chinese universities every month. In the US it is more like 2,000-3,000, in the UK it is 1,500.\n",
      "In terms of patents generally, more are being filed in China than in the rest of the world put together. In 2023China filed 1.7 million patents, against 600,000 in the US. Two decades earlier China had a third of the patents filed b\n"
     ]
    }
   ],
   "source": [
    "with open(\"all_text.txt\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21aad32e-13a8-49dd-ba36-8f483ace7085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK will not be able to resist China's tech dominance China's success in technology has not come out of thin air, even given the unlikely origins of the DeepSeek deep shock. The obscure Hangzhou hedge fund that coded a ChatGPT competitor as a side project it claims cost just $5.6m to train emerges from a concerted effort to invest in future generations of technology. This is not an accident. This is policy. The raw materials of artificial intelligence (AI) are microchips, science PhDs and data. On the latter two, China might be ahead already. There are on average more than 6,000 PhDs in STEM subjects (science, technology, engineering and mathematics) coming out of Chinese universities every month. In the US it is more like 2,000-3,000, in the UK it is 1,500. In terms of patents generally, more are being filed in China than in the rest of the world put together. In 2023China filed 1.7 million patents, against 600,000 in the US. Two decades earlier China had a third of the patents filed b\n"
     ]
    }
   ],
   "source": [
    "# We do a simple cleaning with split(), and then join the list of tokens that\n",
    "# split creates into a string again (whitespace between all the tokens). Perhaps\n",
    "# the quotation marks and other punctuation could be removed too, but we leave\n",
    "# that for now.\n",
    "\n",
    "split = text.split()\n",
    "all_text_cleaned = \" \".join(split)\n",
    "\n",
    "print(all_text_cleaned[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caa2bb49-1777-4bb4-8df2-d3061b8215f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Open a file in write mode (\"w\" = write, \"utf-8\" ensures proper encoding)\n",
    "with open(\"all_text_cleaned.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(all_text_cleaned)  # Write the cleaned text to the file\n",
    "\n",
    "print(\"File saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bbee3-e1ea-4c78-b313-a32fc122337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import SpaCy and load also the English language model.\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea1fc653-0354-422f-a683-ef5172ed2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's process our text with spacy nlp into a doc object. \n",
    "\n",
    "doc_all_text_cleaned = nlp(all_text_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ccf2846-336d-4aa9-8c82-2fe3552431b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(UK, China, China, DeepSeek, Hangzhou, just $5.6, two, China, more than 6,000, STEM, Chinese, every month, US, 2,000-3,000, UK, 1,500, China, 2023China, 1.7 million, 600,000, US, Two decades earlier, China, a third, US, a quarter, Japan, South Korea, Europe, China, US, Chinese, seventh, a decade ago, AI, China, China, Chinese, China, 24/7, AI, China, three-quarters, the start of the century, Last year, the US National Science Board, China, China, United, UK)\n"
     ]
    }
   ],
   "source": [
    "# As we remember from last week, as part of the nlp pipeline, spacy recognizes\n",
    "# and classifies named entities in the text it processes.\n",
    "\n",
    "# There are several ways to access the NE information. Spacy creates a tuple\n",
    "# (which is similar to a list, but cannot be modified) about all the named\n",
    "# entities in doc_book.ents. We can print it:\n",
    "\n",
    "print (doc_all_text_cleaned.ents[:50])\n",
    "\n",
    "# You can try printing what type .ents is: it is a \"tuple\"\n",
    "\n",
    "#print(type(doc_novel.ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddce37a7-ca06-47d8-9c02-72365d14cb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entities tagged with label PERSON are: People, including fictional\n",
      "\n",
      "['Rachel Reeves', 'Trump', 'Keir Starmer', 'Xi', 'Biden', 'Liang Wenfeng', 'Elon Musk', 'Marina Zhang', 'Liang Wenfung', \"Xi Jinping's\", 'Donald Trump', 'Gregory C Allen', 'Mr Allen', 'Ms Zhang', 'Ms Zhang', 'Deepseek', 'Liang Wenfeng', 'Liang', 'Ms Zhang', 'Allen', 'Liang', 'Zhilin Yang', 'Kaiming', 'Wei Sun', 'Getty Images', 'Fiona Zhou', 'Marc Andreessen', 'Sputnik', 'OpenAI', 'Gene Munster', 'OpenAI', 'Sam Altman', 'Oracle', 'Larry Ellison', 'Donald Trump', 'Trump', 'Ellison', \"Liang Wenfung's\", 'High-Flyer', 'Sam Altman', 'Sputnik', 'Reuters DeepSeek', 'OpenAI', 'Donald Trump', 'Kayla Blomquist', 'Qwen', 'Ms Blomquist', 'Donald Trump', 'OpenAI', 'Deepseek', 'Sam Altman', 'GPT-4', 'App Store', 'Ernie', 'Doubao', 'Brandon Drenon', 'Tom Gerken', 'Marc Cieslak', 'Donald Trump', 'OpenAI', 'Deepseek', 'Sam Altman', 'GPT-4', 'App Store', 'Ernie', 'Doubao', 'Liang Wenfeng', 'Liang', 'Li Qiang', 'Liang', 'Liang', 'Liang', 'Wei Sun', 'Marina Zhang', 'Prof Gina Neff', 'Wendy Hall', 'Emmanuel Macron', 'Narendra Modi', 'JD Vance', 'Sam Altman', 'Sundar Pichai', 'Elon Musk', 'Kier Starmer', 'JD Vance', 'Wu Zhaohui', 'Ding Xuexiang', 'Xi JinPing', 'Liang Wenfeng', 'Dario Amodei', 'Getty Images', 'Geoffrey Hinton', 'Prof Hinton', 'Prof Max Tegmark', 'Holly Wang', 'Holly', 'Holly', 'Holly', 'Covid', 'Holly', 'Getty Images DeepSeek', 'Nan Jia', 'Nan', 'John', 'Deepseek', 'Fang Kecheng', 'Prof Fang', 'Covid', 'Prof Nan', 'Yang', 'Andrew Duncanis', 'Sam Altman', 'GPT-4', 'Biden', 'Liang Wenfeng', 'OpenAI', 'Monte Carlo Tree Search', 'Getty Images Modified', 'Donald Trump', 'Winston Churchill', 'Hu Xijin', 'Liang Wenfeng', 'Glass', 'Bryan R. Smith', 'Li Chengdong', 'Fancaiju', 'George Soros', 'Trump', 'Fancaiju', 'Tom Zhang', 'Kaifu Lee', 'Lee', 'Liang', 'Liang', 'Liang', 'OpenAI', 'Liang', 'Liang', 'Jensen Huang', 'Stella Kalinina', 'Liang', 'Li Qiang', 'Liang', 'Xi Jinping', 'Xi', 'Zhang Fuyu', 'Xi Jinping', 'Li Yuan', 'Li Yuan', 'Sputnik', 'Marc Andreessen', 'High-Flyer', 'Googles Gemini', 'Liang Wenfeng', 'OpenAI', 'Top A.I.', 'Tim Dettmers', 'Jensen Huang', 'Stella Kalinina', 'Biden', 'Jimmy Carter', 'Xi Jinping', 'Xi', 'Pedro Pardo', 'Jack Stubbs', 'Claude', 'Xi Jinping', 'Daniel Berehulak', 'Zhang Jun.', 'Graphika', 'Safeguard Defenders', 'Laura Harth', 'OpenAI', 'Lutz Finger', 'Bill Gurley', 'Googles AI', 'Zack Kass', 'OpenAI', 'querying ChatGPT', 'Covid', 'Xi Zhongxun', 'Xi', 'Li Qiang', 'Li', 'Zhao Ziyang', 'Bo Xilai', 'Xi', 'Cai Qi', 'Xi', 'Tim Dettmers', 'Daron Acemoglu', 'Acemoglu', 'Acemoglu', 'Elon Musk', 'Musk', 'Optimus', 'Musk', 'Musk', 'DeepSeek’s A.I.', 'Aswath Damodaran', 'Palantir', 'Shyam Sankar', 'Alexander Karp', 'Karp', 'Musk', 'Musk', 'Karp', 'Damodaran', 'Acemoglu', 'Tesla', 'Pavel Durov', 'Xi Jinping', 'Yiran Chen', 'Gilles Sabrié', 'Damien Ma', 'Ma', 'Ma', 'Marina Zhang', 'Liang Wenfeng', 'Yanbo Wang', 'Andy Wong', 'Liang', 'Liang', 'Liang', 'Siyi Zhao', 'Vivian Wang', 'Vivian Wang', 'Khan', 'Biden', 'Marc Andreessen', 'Andreessen', 'Clinton', 'Biden', 'Lina M. Khan', 'Biden', 'Satya Nadella', 'Jevons', 'William Stanley Jevons', 'Jevons', 'Nadella', 'Nadella', 'Jevons', 'Jevons', 'Ahn Young-Joon/', 'Meaghan Tobin', 'Jin Yu', 'Meaghan Tobin', 'Jin Yu Young', 'Liang Wenfeng', 'Xi Jinping', 'Guo Jiakun', 'Guo', 'Kevin Roose', 'Kevin', 'Kevin', 'App Store', 'OpenAI', 'Kevin', 'Kevin', 'Kevin', 'Kevin', 'Kevin', 'Kevin', 'Xi Jinping', 'Kevin', 'Sputnik', 'Sputnik', 'Kevin', 'Trump', 'Claudia Sheinbaum', 'Trump', 'Trump', 'Jordan Jacobs', 'Jacobs', 'Jacobs', 'Pfizer', 'Anthropic’s Claude', 'Matt Turck', 'OpenAI', 'Marc Andreessen', 'Marc Andreessen', 'Mike Kai Chen', 'Eric Vishria', 'Benchmark', 'Anjney Midha', 'Gavin Baker', 'Musk', 'Baker', 'Biden’s', 'Turck', 'Niko Bonatsos', 'Niko Bonatsos', 'Kimberly White/Getty Images', 'Bonatsos', 'Bonatsos', 'Clément Delangue', 'Jacobs', 'Mark Zuckerberg', 'Anat Ashkenazi', 'Deploying A.I.', 'Satya Nadella', 'Andy Jassy', 'Jassy', 'Nadella', 'Ashkenazi', 'Zuckerberg', 'Meta', 'Greg Baker', 'Anthropic’s Claude', 'Claude', 'Claude', 'Liang Wenfeng', 'Liang', 'Liang Wenfeng', 'Liang', 'Liang', 'Liang', 'Sam Altman', 'Liang', 'Pony Ma', 'Liangs', 'Liangs', 'Aly Song/Reuters Later', 'Peter Alexander', 'Alexander', 'Chinas', 'Chinas A.I.', 'Liang', 'Liang', 'Liangs', 'Liang', 'Apples App Store', 'Ragavan Srinivasan', 'Meta', 'Chris V. Nicholson', 'Meta', 'Nicholson', 'Yann LcCun', 'Yann LeCun', 'Victor Llorente', 'Yann LeCun', 'LeCun', 'Kai-Fu Lee', 'Clément Delangue', 'Sputnik', 'Xi Jinping', 'Xi', 'Xi', 'Xi', 'Ke Jie', 'Wu Hong/European Pressphoto Agency', 'Matt Sheehan', 'Sheehan', 'Liang Wenfeng', 'Li Qiang', 'Liang', 'Liang Wenfeng', 'Li Qiang', 'Sun Chenghao', 'Xi', 'Sheehan', 'Qilai Shen', 'Gregory C. Allen', 'Allen', 'Andrew Yao', 'Xi', 'Barath Harithas', 'Harithas', 'OpenAI', 'Liz Bourgeois', 'OpenAI', 'Greg Brockman', 'Zack Kass', 'OpenAI', 'Sam Altman', 'Kevin Weil', 'Gil Luria', 'Sundar Pichai', 'Mark Zuckerberg', 'Luria', 'Eric Schmidt', 'Kass', 'Sam Altman', 'Gil Luria', 'D.A. Davidson', 'the Sam Altmans', 'Mark Zuckerbergs', 'GPT-4', 'OpenAI', 'GPT-4', 'Trump', 'Luria', 'Luria', 'Luria', 'GPT-4', 'Googles Gemini', 'Liang Wenfeng', 'Li Qiang', 'Isaac Stone', 'Aaron Snoswell', 'Ernie Bot', 'Sam Altman', 'X.', 'Moonshot AI', 'Moonshot AI', 'Kimi', 'Doubao', 'Ernie Bot', 'Anthropic’s Claude', 'Ernie Bot', 'Marc Andreessen', 'Liang Wenfeng', 'Liang', 'Sam Altman', 'Andreessen', 'Andreessen Horowitz', 'X.', 'Joe Biden', 'Donald Trump', 'Nvidia', 'Meta', 'Broadcom', 'Palantir', 'Oracle', 'Keith Lerner', 'Giuseppe Sette', 'Apples App Store', 'JD Vance', 'Oren Etzioni', 'DeepMind', 'Demis Hassabis', 'Satya Nadella', 'Tim Cook', 'OpenAI', 'Etzioni', 'Lewis Tunstall', 'Tunstall', 'Nadella', 'Qualcomm', 'Durga Malladi', 'Tunstall', 'Grok 3', 'Elon Musk', 'Etzioni', 'Googles Gemini', 'Donald Trump', 'Biden', 'John Villasenor', 'Trump', 'Joe Biden', 'Gary Marcus', 'Trump', 'Trump', 'Trump', 'Ed Mills', 'Raymond James', 'Marco Rubio', 'Trump', 'a Sputnik Moment', 'Jeffrey Sonnenfeld', 'Alexandr Wang', 'Art Hogan', 'Hogan', 'Jake Sullivan', 'Biden', 'Sullivan', 'Sullivan', 'Sullivan', 'Darin LaHood', 'Josh Gottheimer', 'Flyer', 'Donald Trump', 'Gottheimer', 'Liang Wenfeng', 'Liang', 'High-Flyer Quant', 'GPT-4', 'Googles Gemini', 'Marc Andreessen', 'Sputnik', 'Donald Trump', 'Beijings', 'Flyer Quant', 'Liang', 'Yicai', 'Liang', 'Liang', 'High-Flyer Quant', 'Liang', 'Liang', 'Liang', 'Liang', 'Liang', 'Zihan Wang', 'Tony Burke', 'Anthony Albanese', 'Baidus Kunlunxin', 'Beyond', 'Liang Wenfeng', 'Li Qiang', 'Lian Jye Su', 'Su', 'Deepseek', 'Liang Wenfeng', 'Linghao Bao', 'Googles', 'Sam Altman', 'Marc Andreessen', 'Donald Trump', 'X.', 'Nvidia', 'Googles', 'Oracle', 'Vertiv', 'Keith Lerner', 'Lerner', 'Charu Chanana', 'Michael Block', 'Giuseppe Sette']\n"
     ]
    }
   ],
   "source": [
    "# Here we create a list with all the person names. The attribute .label has the\n",
    "# NE class (GPE, PERSON etc.). The attribute .text stores the actual entity as\n",
    "# a string variable.\n",
    "\n",
    "# In a for loop, we iterate through all the recognised named entities, check with\n",
    "# \"if\" if the entity is a \"PERSON\", and if yes, we store the entity into our list\n",
    "# \"list_persons\"\n",
    "\n",
    "list_persons = []\n",
    "\n",
    "for entity in doc_all_text_cleaned.ents:\n",
    "    if entity.label_ == \"PERSON\":          # We use the class \"PERSON\" here (could be any other NE class too)\n",
    "        list_persons.append(entity.text)\n",
    "\n",
    "print(f\"The entities tagged with label PERSON are: {spacy.explain('PERSON')}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(list_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46998511-8166-4ccf-9081-a5d94027caa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entities tagged with label PERSON are: People, including fictional\n",
      "\n",
      "Rachel Reeves: 1\n",
      "Trump: 12\n",
      "Keir Starmer: 1\n",
      "Xi: 11\n",
      "Biden: 8\n",
      "Liang Wenfeng: 18\n",
      "Elon Musk: 4\n",
      "Marina Zhang: 3\n",
      "Liang Wenfung: 1\n",
      "Xi Jinping's: 1\n",
      "Donald Trump: 11\n",
      "Gregory C Allen: 1\n",
      "Mr Allen: 1\n",
      "Ms Zhang: 3\n",
      "Deepseek: 5\n",
      "Liang: 35\n",
      "Allen: 2\n",
      "Zhilin Yang: 1\n",
      "Kaiming: 1\n",
      "Wei Sun: 2\n",
      "Getty Images: 2\n",
      "Fiona Zhou: 1\n",
      "Marc Andreessen: 8\n",
      "Sputnik: 7\n",
      "OpenAI: 17\n",
      "Gene Munster: 1\n",
      "Sam Altman: 12\n",
      "Oracle: 3\n",
      "Larry Ellison: 1\n",
      "Ellison: 1\n",
      "Liang Wenfung's: 1\n",
      "High-Flyer: 2\n",
      "Reuters DeepSeek: 1\n",
      "Kayla Blomquist: 1\n",
      "Qwen: 1\n",
      "Ms Blomquist: 1\n",
      "GPT-4: 7\n",
      "App Store: 3\n",
      "Ernie: 2\n",
      "Doubao: 3\n",
      "Brandon Drenon: 1\n",
      "Tom Gerken: 1\n",
      "Marc Cieslak: 1\n",
      "Li Qiang: 7\n",
      "Prof Gina Neff: 1\n",
      "Wendy Hall: 1\n",
      "Emmanuel Macron: 1\n",
      "Narendra Modi: 1\n",
      "JD Vance: 3\n",
      "Sundar Pichai: 2\n",
      "Kier Starmer: 1\n",
      "Wu Zhaohui: 1\n",
      "Ding Xuexiang: 1\n",
      "Xi JinPing: 1\n",
      "Dario Amodei: 1\n",
      "Geoffrey Hinton: 1\n",
      "Prof Hinton: 1\n",
      "Prof Max Tegmark: 1\n",
      "Holly Wang: 1\n",
      "Holly: 4\n",
      "Covid: 3\n",
      "Getty Images DeepSeek: 1\n",
      "Nan Jia: 1\n",
      "Nan: 1\n",
      "John: 1\n",
      "Fang Kecheng: 1\n",
      "Prof Fang: 1\n",
      "Prof Nan: 1\n",
      "Yang: 1\n",
      "Andrew Duncanis: 1\n",
      "Monte Carlo Tree Search: 1\n",
      "Getty Images Modified: 1\n",
      "Winston Churchill: 1\n",
      "Hu Xijin: 1\n",
      "Glass: 1\n",
      "Bryan R. Smith: 1\n",
      "Li Chengdong: 1\n",
      "Fancaiju: 2\n",
      "George Soros: 1\n",
      "Tom Zhang: 1\n",
      "Kaifu Lee: 1\n",
      "Lee: 1\n",
      "Jensen Huang: 2\n",
      "Stella Kalinina: 2\n",
      "Xi Jinping: 8\n",
      "Zhang Fuyu: 1\n",
      "Li Yuan: 2\n",
      "Googles Gemini: 4\n",
      "Top A.I.: 1\n",
      "Tim Dettmers: 2\n",
      "Jimmy Carter: 1\n",
      "Pedro Pardo: 1\n",
      "Jack Stubbs: 1\n",
      "Claude: 3\n",
      "Daniel Berehulak: 1\n",
      "Zhang Jun.: 1\n",
      "Graphika: 1\n",
      "Safeguard Defenders: 1\n",
      "Laura Harth: 1\n",
      "Lutz Finger: 1\n",
      "Bill Gurley: 1\n",
      "Googles AI: 1\n",
      "Zack Kass: 2\n",
      "querying ChatGPT: 1\n",
      "Xi Zhongxun: 1\n",
      "Li: 1\n",
      "Zhao Ziyang: 1\n",
      "Bo Xilai: 1\n",
      "Cai Qi: 1\n",
      "Daron Acemoglu: 1\n",
      "Acemoglu: 3\n",
      "Musk: 6\n",
      "Optimus: 1\n",
      "DeepSeek’s A.I.: 1\n",
      "Aswath Damodaran: 1\n",
      "Palantir: 2\n",
      "Shyam Sankar: 1\n",
      "Alexander Karp: 1\n",
      "Karp: 2\n",
      "Damodaran: 1\n",
      "Tesla: 1\n",
      "Pavel Durov: 1\n",
      "Yiran Chen: 1\n",
      "Gilles Sabrié: 1\n",
      "Damien Ma: 1\n",
      "Ma: 2\n",
      "Yanbo Wang: 1\n",
      "Andy Wong: 1\n",
      "Siyi Zhao: 1\n",
      "Vivian Wang: 2\n",
      "Khan: 1\n",
      "Andreessen: 2\n",
      "Clinton: 1\n",
      "Lina M. Khan: 1\n",
      "Satya Nadella: 3\n",
      "Jevons: 4\n",
      "William Stanley Jevons: 1\n",
      "Nadella: 4\n",
      "Ahn Young-Joon/: 1\n",
      "Meaghan Tobin: 2\n",
      "Jin Yu: 1\n",
      "Jin Yu Young: 1\n",
      "Guo Jiakun: 1\n",
      "Guo: 1\n",
      "Kevin Roose: 1\n",
      "Kevin: 10\n",
      "Claudia Sheinbaum: 1\n",
      "Jordan Jacobs: 1\n",
      "Jacobs: 3\n",
      "Pfizer: 1\n",
      "Anthropic’s Claude: 3\n",
      "Matt Turck: 1\n",
      "Mike Kai Chen: 1\n",
      "Eric Vishria: 1\n",
      "Benchmark: 1\n",
      "Anjney Midha: 1\n",
      "Gavin Baker: 1\n",
      "Baker: 1\n",
      "Biden’s: 1\n",
      "Turck: 1\n",
      "Niko Bonatsos: 2\n",
      "Kimberly White/Getty Images: 1\n",
      "Bonatsos: 2\n",
      "Clément Delangue: 2\n",
      "Mark Zuckerberg: 2\n",
      "Anat Ashkenazi: 1\n",
      "Deploying A.I.: 1\n",
      "Andy Jassy: 1\n",
      "Jassy: 1\n",
      "Ashkenazi: 1\n",
      "Zuckerberg: 1\n",
      "Meta: 4\n",
      "Greg Baker: 1\n",
      "Pony Ma: 1\n",
      "Liangs: 3\n",
      "Aly Song/Reuters Later: 1\n",
      "Peter Alexander: 1\n",
      "Alexander: 1\n",
      "Chinas: 1\n",
      "Chinas A.I.: 1\n",
      "Apples App Store: 2\n",
      "Ragavan Srinivasan: 1\n",
      "Chris V. Nicholson: 1\n",
      "Nicholson: 1\n",
      "Yann LcCun: 1\n",
      "Yann LeCun: 2\n",
      "Victor Llorente: 1\n",
      "LeCun: 1\n",
      "Kai-Fu Lee: 1\n",
      "Ke Jie: 1\n",
      "Wu Hong/European Pressphoto Agency: 1\n",
      "Matt Sheehan: 1\n",
      "Sheehan: 2\n",
      "Sun Chenghao: 1\n",
      "Qilai Shen: 1\n",
      "Gregory C. Allen: 1\n",
      "Andrew Yao: 1\n",
      "Barath Harithas: 1\n",
      "Harithas: 1\n",
      "Liz Bourgeois: 1\n",
      "Greg Brockman: 1\n",
      "Kevin Weil: 1\n",
      "Gil Luria: 2\n",
      "Luria: 4\n",
      "Eric Schmidt: 1\n",
      "Kass: 1\n",
      "D.A. Davidson: 1\n",
      "the Sam Altmans: 1\n",
      "Mark Zuckerbergs: 1\n",
      "Isaac Stone: 1\n",
      "Aaron Snoswell: 1\n",
      "Ernie Bot: 3\n",
      "X.: 3\n",
      "Moonshot AI: 2\n",
      "Kimi: 1\n",
      "Andreessen Horowitz: 1\n",
      "Joe Biden: 2\n",
      "Nvidia: 2\n",
      "Broadcom: 1\n",
      "Keith Lerner: 2\n",
      "Giuseppe Sette: 2\n",
      "Oren Etzioni: 1\n",
      "DeepMind: 1\n",
      "Demis Hassabis: 1\n",
      "Tim Cook: 1\n",
      "Etzioni: 2\n",
      "Lewis Tunstall: 1\n",
      "Tunstall: 2\n",
      "Qualcomm: 1\n",
      "Durga Malladi: 1\n",
      "Grok 3: 1\n",
      "John Villasenor: 1\n",
      "Gary Marcus: 1\n",
      "Ed Mills: 1\n",
      "Raymond James: 1\n",
      "Marco Rubio: 1\n",
      "a Sputnik Moment: 1\n",
      "Jeffrey Sonnenfeld: 1\n",
      "Alexandr Wang: 1\n",
      "Art Hogan: 1\n",
      "Hogan: 1\n",
      "Jake Sullivan: 1\n",
      "Sullivan: 3\n",
      "Darin LaHood: 1\n",
      "Josh Gottheimer: 1\n",
      "Flyer: 1\n",
      "Gottheimer: 1\n",
      "High-Flyer Quant: 2\n",
      "Beijings: 1\n",
      "Flyer Quant: 1\n",
      "Yicai: 1\n",
      "Zihan Wang: 1\n",
      "Tony Burke: 1\n",
      "Anthony Albanese: 1\n",
      "Baidus Kunlunxin: 1\n",
      "Beyond: 1\n",
      "Lian Jye Su: 1\n",
      "Su: 1\n",
      "Linghao Bao: 1\n",
      "Googles: 2\n",
      "Vertiv: 1\n",
      "Lerner: 1\n",
      "Charu Chanana: 1\n",
      "Michael Block: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count occurrences of each unique name\n",
    "name_frequencies = Counter(list_persons)\n",
    "\n",
    "# Print explanation of \"PERSON\" tag\n",
    "print(f\"The entities tagged with label PERSON are: {spacy.explain('PERSON')}\\n\")\n",
    "\n",
    "# Print names with their frequencies\n",
    "for name, count in name_frequencies.items():\n",
    "    print(f\"{name}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8312372d-1a7d-4663-8792-8c2ecd41525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 person named entites and their frequencies: [('Liang', 35), ('Liang Wenfeng', 18), ('OpenAI', 17), ('Trump', 12), ('Sam Altman', 12), ('Xi', 11), ('Donald Trump', 11), ('Kevin', 10), ('Biden', 8), ('Marc Andreessen', 8)]\n"
     ]
    }
   ],
   "source": [
    "# Here we print only the 10 most common strings in the list:\n",
    "\n",
    "print (\"Top 10 person named entites and their frequencies: \" + str(Counter(list_persons).most_common(10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "205166db-e29b-48d7-9952-414f496f1e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liang</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liang Wenfeng</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xi</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kevin</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Biden</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marc Andreessen</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            person  count\n",
       "0            Liang     35\n",
       "1    Liang Wenfeng     18\n",
       "2           OpenAI     17\n",
       "3            Trump     12\n",
       "4       Sam Altman     12\n",
       "5               Xi     11\n",
       "6     Donald Trump     11\n",
       "7            Kevin     10\n",
       "8            Biden      8\n",
       "9  Marc Andreessen      8"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "persons_counted = Counter(list_persons)\n",
    "\n",
    "df = pd.DataFrame(persons_counted.most_common(), columns=['person', 'count'])\n",
    "\n",
    "df[0:10] # We print twenty first entries in our dataframe, thus, top twenty counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b88e4138-b0e7-405f-b7ff-20e591e020d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 person named entities and their frequencies:  [('Liang Wenfeng', 54), ('Donald Trump', 23), ('Xi Jinping', 19), ('OpenAI', 17), ('Sam Altman', 12), ('Kevin', 10), ('Biden', 8), ('Marc Andreessen', 8), ('Sputnik', 7), ('GPT-4', 7)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Merging counts manually in the list_persons\n",
    "# Merge \"Liang\" with \"Liang Wenfeng\"\n",
    "for i in range(len(list_persons)):\n",
    "    if list_persons[i] == \"Liang\" or list_persons[i] == \"Liang Wenfung\":\n",
    "        list_persons[i] = \"Liang Wenfeng\"  # Replace \"Liang\" with \"Liang Wenfeng\"\n",
    "\n",
    "# Merge \"Trump\" with \"Donald Trump\"\n",
    "for i in range(len(list_persons)):\n",
    "    if list_persons[i] == \"Trump\":\n",
    "        list_persons[i] = \"Donald Trump\"  # Replace \"Trump\" with \"Donald Trump\"\n",
    "        \n",
    "# Merge \"Xi\" with \"Xi Jinping\"\n",
    "for i in range(len(list_persons)):\n",
    "    if list_persons[i] == \"Xi\":\n",
    "        list_persons[i] = \"Xi Jinping\" # Replace \"Xi\" with \"Xi Jinping\"\n",
    "\n",
    "# Print the updated top 10 person named entities and their frequencies\n",
    "top_10_persons = Counter(list_persons).most_common(10)\n",
    "print(\"Top 10 person named entities and their frequencies: \", top_10_persons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae225f02-0e44-4916-87ab-338276d27d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liang Wenfeng</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xi Jinping</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kevin</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Biden</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Marc Andreessen</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sputnik</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            person  count\n",
       "0    Liang Wenfeng     54\n",
       "1     Donald Trump     23\n",
       "2       Xi Jinping     19\n",
       "3           OpenAI     17\n",
       "4       Sam Altman     12\n",
       "5            Kevin     10\n",
       "6            Biden      8\n",
       "7  Marc Andreessen      8\n",
       "8          Sputnik      7\n",
       "9            GPT-4      7"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons_counted = Counter(list_persons)\n",
    "\n",
    "df = pd.DataFrame(persons_counted.most_common(), columns=['person', 'count'])\n",
    "\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c18237f7-9a99-49d7-ab58-afbe578e426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjectives in the text: ['able', 'tech', 'thin', 'unlikely', 'deep', 'obscure', 'ChatGPT', 'concerted', 'future', 'raw', 'artificial', 'latter', 'average', 'more', 'Chinese', 'new', 'scientific', 'Chinese', 'electric', 'visible', 'electric', 'biggest', 'Chinese', 'electric', 'intelligent', 'conventional', 'dark', 'astonishing', 'clean', 'Last', 'artificial', 'more', 'more', 'indigenous', 'electric', 'complete', 'own', 'Tube', 'Chinese', 'extraordinary', 'difficult', 'concerned', 'problematic', 'positive', 'prominent', 'first', 'obvious', 'long', 'national', 'deeper']\n"
     ]
    }
   ],
   "source": [
    "# List to store adjectives\n",
    "adjectives = []\n",
    "\n",
    "# Loop through the tokens in the processed document\n",
    "for token in doc_all_text_cleaned:\n",
    "    # Check if the token is an adjective (POS tag \"ADJ\")\n",
    "    if token.pos_ == \"ADJ\":\n",
    "        adjectives.append(token.text)\n",
    "\n",
    "# Print the list of adjectives\n",
    "print(\"Adjectives in the text:\", adjectives[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ee8a8e16-ae63-45b7-b730-aa465151c361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>akjectives</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>more</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>many</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>American</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>last</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>artificial</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>powerful</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>open</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>own</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>such</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>same</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>global</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>good</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>able</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>less</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>free</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>advanced</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>top</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>social</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>big</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>efficient</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>recent</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>real</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>national</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>high</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>first</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>much</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>large</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>few</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cheaper</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>technological</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>best</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>major</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>biggest</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>huge</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>chief</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>latest</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>significant</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>possible</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>better</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>similar</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>most</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>several</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>long</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>economic</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>available</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>fewer</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>massive</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       akjectives  count\n",
       "0         Chinese    236\n",
       "1            more     97\n",
       "2           other     90\n",
       "3             new     87\n",
       "4            many     80\n",
       "5        American     68\n",
       "6            last     67\n",
       "7      artificial     61\n",
       "8        powerful     56\n",
       "9            open     56\n",
       "10            own     49\n",
       "11           such     40\n",
       "12           same     36\n",
       "13         global     35\n",
       "14           good     34\n",
       "15           able     31\n",
       "16           less     29\n",
       "17           free     29\n",
       "18       advanced     28\n",
       "19            top     28\n",
       "20         social     26\n",
       "21            big     26\n",
       "22      efficient     26\n",
       "23         recent     25\n",
       "24           real     25\n",
       "25       national     24\n",
       "26           high     23\n",
       "27          first     22\n",
       "28           much     22\n",
       "29          large     22\n",
       "30            few     22\n",
       "31        cheaper     21\n",
       "32  technological     21\n",
       "33           best     21\n",
       "34          major     21\n",
       "35        biggest     20\n",
       "36           huge     20\n",
       "37          chief     20\n",
       "38         latest     19\n",
       "39    significant     19\n",
       "40       possible     18\n",
       "41         better     18\n",
       "42        similar     18\n",
       "43           most     17\n",
       "44        several     16\n",
       "45           long     15\n",
       "46       economic     15\n",
       "47      available     15\n",
       "48          fewer     15\n",
       "49        massive     15"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_counted = Counter(adjectives)\n",
    "\n",
    "df = pd.DataFrame(adj_counted.most_common(), columns=['akjectives', 'count'])\n",
    "\n",
    "df[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9d848-9d79-4c2a-9a37-29432629e8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (numpy_env)",
   "language": "python",
   "name": "numpy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
