What DeepSeek? Big Tech Keeps Its A.I. Building Boom Alive.An apparent breakthrough in efficiency from the Chinese start-up did not make tech’s biggest companies question their extravagant spending on new data centers.A data center being built in front of snow-capped mountains.Construction for a new Microsoft data center in East Wenatchee, Wash.Sign up for the On Tech newsletter.   Get our best tech reporting from the week. Get it sent to your inbox.Wall Street went into panic mode about two weeks ago after the Chinese start-up DeepSeek released an artificial intelligence system that appeared to be radically more efficient than what its American competitors had built.The investors who had pumped trillions of dollars into tech stocks over the last few years worried whether the tens of billions of dollars that tech companies were spending on new data centers suddenly looked like comic overkill.But the biggest tech companies made clear in recent earnings reports that they believe there may be no such thing as overkill when it comes to new data centers.Amazon implied on Thursday that its capital expenditures — a figure that includes data center construction and other items like warehouses — could top $100 billion this year. Microsoft said its spending could surpass $80 billion. Alphabet said it would spend $75 billion, and Meta reaffirmed plans to have capital spending hit as much as $65 billion.Combined, they could spend roughly $100 billion more than last year on these projects.Executives urged patience. The problem right now, they said, is that customers want more A.I. than the companies can supply. And the only way they can meet demand is to build as much as they can as quickly as they can.“Whenever I see someone else do something better, I say, ‘Ugh, we should have done that,’” Mark Zuckerberg, Meta’s chief executive, told employees at a companywide meeting last week, according to a recording obtained by The New York Times. “Competition is good,” he added, “but we need to make sure that we win.”Here are some key points to understand this spend-happy moment for tech:Tech companies need more data centers than they have.Many of the companies say they’re constrained by the supply of chips, land and power needed to build data centers, and are racing to get more of them open. Microsoft, Alphabet and Amazon all said they could have had higher cloud computing sales if they had the capacity. Cloud services are the typical way A.I. is delivered to customers.Alphabet saw “demand that exceeds our available capacity,” Anat Ashkenazi, Alphabet’s finance chief, told investors. “So we’ll be working hard to address that and make sure we bring more capacity online.”Microsoft has been saying it has been constrained for a while, and previously told investors that the pressure would ease early this year. But last week, when it reported its latest earnings, executives told investors that it might take until summer to get enough capacity up and running to meet the full demand. Its stock fell about 5 percent in after-hours trading after the report.They say greater efficiency will expand the use and demand for A.I.While many people think about data centers as the enormously expensive, power-hungry places where advanced A.I. systems are developed, they are also where A.I. is deployed. Those are two different steps: training a model that underpins ChatGPT, versus asking ChatGPT for a recipe suggestion.Deploying A.I. is known as “inferencing” in the industry; it is where, the tech companies increasingly say, their businesses will boom.As costs come down, “A.I. will be much more ubiquitous,” Satya Nadella, Microsoft’s chief executive, told investors last week.Andy Jassy, Amazon’s chief executive, told investors on Thursday that while a world where every app was infused with A.I. could be hard to fathom, “this is the world we’re thinking about all the time.” That vision, he said, has inferencing at its core.He argued that lowering the costs of inferencing would follow the pattern of previous technological trends: As the systems become less expensive to deploy, Mr. Jassy said, customers will “get excited about what else they could build that they always thought was cost-prohibitive before, and they usually end up spending a lot more in total.”The companies say they have to think about the long haul.Cloud providers are used to giving customers the illusion of endless supply, which means they must juggle having just enough data centers online to stream the video you want or answer your chatbot query. But they also can’t build too far in advance, locking up billions of dollars that could be deployed elsewhere. Balancing those two — particularly when securing land, chips and power for data centers can take years — is one of the enormous challenges the companies face.Executives have argued that they can adapt how they use the investments, between building and deploying A.I. models, and between serving their own core business and those of customers. Mr. Nadella said Microsoft’s infrastructure was “pretty fungible.” Ms. Ashkenazi said Google was also flexible. It could, for example, “repurpose capacity” to serve Google Search instead of cloud customers.Mr. Zuckerberg said that Meta was studying DeepSeek and the ways it created efficiencies, but that investing heavily in data centers would be a strategic advantage against a small and nimble competitor.“We serve a billion-plus people — that’s just a lot of people, so more and more of the fleet is going toward running inference,” he told employees.Regardless of the explanation, cutting into profits — even the gaudy profits of tech’s biggest companies — is unlikely to thrill investors. Every company saw its share price fall after its earnings report.