{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2fa3c-fcad-4191-8a52-70c786d23d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: bertopic 0.16.4\n",
      "Uninstalling bertopic-0.16.4:\n",
      "  Would remove:\n",
      "    /usr/local/anaconda3/lib/python3.12/site-packages/bertopic-0.16.4.dist-info/*\n",
      "    /usr/local/anaconda3/lib/python3.12/site-packages/bertopic/*\n",
      "Proceed (Y/n)? "
     ]
    }
   ],
   "source": [
    "!pip uninstall bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d55db8-7e56-4dd3-b608-c550c8efbe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83e2fe-7a62-4256-83f2-979cce79a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory where your text files are stored\n",
    "directory = \"./rawcorpus\"  # Change this to the path where your files are\n",
    "\n",
    "# List to store the article texts\n",
    "docs = []\n",
    "\n",
    "# Loop over the files and directories in the given directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".txt\"):  # Ensure we're only reading .txt files\n",
    "            file_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    docs.append(file.read())  # Append each file's content to the docs list\n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='latin-1') as file:\n",
    "                        docs.append(file.read())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824fcb4-4283-4f30-8d9c-792c82874d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sources = [\"BBC\", \"NYT\", \"CNN\"]  # Corresponding labels for each article\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bebd2f7-a045-4a44-9a5c-8c32a31ecaaf",
   "metadata": {},
   "source": [
    "the code I provided will automatically process each .txt file in the specified directory, clean up the text, and store it in the docs list.split(): This method splits the text (the string novel) into individual words (tokens), using whitespace as the delimiter. It automatically ignores multiple consecutive spaces, so if there are extra spaces between words, they are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8148c-b3a4-49e4-add9-456cb7f81c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory where your text files are stored\n",
    "directory = \"./raw_corpus\"  \n",
    "\n",
    "# List to store the article texts\n",
    "docs = []\n",
    "\n",
    "# Loop over the files and directories in the given directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".txt\"):  # Ensure we're only reading .txt files\n",
    "            file_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()  # Read the content of the file\n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='latin-1') as file:\n",
    "                        content = file.read()  # Read the content of the file\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Step 1: Split the text into words (splitting by any whitespace)\n",
    "            split_content = content.split()  # This automatically handles extra spaces\n",
    "\n",
    "            # Step 2: Join the words back into a single string with a single space\n",
    "            cleaned_content = \" \".join(split_content)  # Re-join words with a single space\n",
    "\n",
    "            # Step 3: Append cleaned content to the docs list\n",
    "            docs.append(cleaned_content)\n",
    "\n",
    "# Now `docs` contains all the cleaned articles (no extra spaces or blank lines)\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74ac45-5bf9-49db-85cf-0c669f10402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "# Initialize the BERTopic model\n",
    "topic_model = BERTopic()\n",
    "\n",
    "# Fit the model to your documents\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# Check the topic distribution\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0d1df-d3ca-46a9-90b1-288efa097f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b0544-d1f0-45ac-8908-99536774b7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11065fea-56dd-4820-8ebb-3c9241a51531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bertopic_env)",
   "language": "python",
   "name": "bertopic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
